{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Orbis - Astronomer Software Deployment Compute Report Generator","text":"<p>Orbis is a deployment compute report generator tool that analyzes data from Astronomer Software to provide insights into deployment metrics and resource utilization.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Comprehensive deployment metrics analysis</li> <li>Resource utilization tracking</li> <li>Custom resource allocation support</li> <li>PDF report generation</li> <li>Docker-based deployment for easy setup</li> </ul>"},{"location":"#quick-start-with-docker-recommended","title":"Quick Start with Docker (Recommended)","text":"<ol> <li>Create a <code>.env</code> file with your configuration:    <pre><code>ASTRO_SOFTWARE_API_TOKEN=your_token_here\n</code></pre></li> </ol> <p>Warning</p> <p>Please use <code>SYSTEM_ADMIN</code> level token otherwise Orbis won't be able to query Prometheus and will result in empty metrics. Ref</p> <ol> <li>Run Orbis using Docker:    <pre><code>docker run --pull always --rm -it \\\n  --env-file .env \\\n  -v $(pwd)/output:/app/output \\\n  quay.io/astronomer/orbis:0.7.0 orbis compute-software \\\n  -s START_DATE \\\n  -e END_DATE \\\n  -o ORGANIZATION_ID \\\n  [-v] [-w WORKSPACES] [-z] [-r] [-p]\n</code></pre></li> </ol>"},{"location":"#documentation-sections","title":"Documentation Sections","text":"<ul> <li>Installation</li> <li>Usage Guide</li> <li>Modules<ul> <li>API<ul> <li>Houston</li> <li>Prometheus</li> </ul> </li> <li>Report<ul> <li>Generator</li> <li>Visualizer</li> <li>CSV Generator</li> </ul> </li> <li>Data Models</li> </ul> </li> <li>Reports</li> </ul>"},{"location":"#support","title":"Support","text":"<p>For support, please contact success@astronomer.io</p>"},{"location":"installation/","title":"Installation Guide","text":""},{"location":"installation/#1-docker-recommended","title":"1. Docker (Recommended)","text":"<p>The recommended way to run Orbis is using Docker. This ensures consistent behavior across different environments and simplifies the setup process.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install Docker</li> <li>Ensure you have a valid Houston API token (with <code>SYSTEM_ADMIN</code> role) for authentication    (If only 1 workspace is specified, then you can use <code>WORKSPACE_ADMIN</code> token instead)</li> </ol>"},{"location":"installation/#docker-setup","title":"Docker Setup","text":"<pre><code># Pull the latest version\ndocker pull quay.io/astronomer/orbis:0.7.0\n</code></pre> <p>Create a <code>.env</code> file with your configuration:</p> <pre><code>ASTRO_SOFTWARE_API_TOKEN=your_token_here\n</code></pre>"},{"location":"installation/#2-orbis-cli-binary","title":"2. Orbis CLI Binary","text":"<p>Warning</p> <p>Binaries are currently experimental.</p> <p>If you prefer to run Orbis directly on your system, you can request the binary package from Astronomer. We provide pre-built binaries for:</p> <ul> <li>Linux (x86_64)</li> <li>macOS (x86_64, arm64)</li> <li>Windows (x86_64)</li> </ul> <p>Please contact your Astronomer representative to obtain the appropriate binary for your platform. They will provide you with:</p> <ol> <li>The binary package for your operating system</li> <li>Instructions for setting up environment variables</li> <li>Any additional configuration requirements</li> </ol>"},{"location":"installation/#configuration","title":"Configuration","text":"<p>After installation, you'll need to configure Orbis with your credentials. You will need:</p> <ol> <li>A valid Houston API token (with <code>SYSTEM_ADMIN</code> role) (Or <code>WORKSPACE_ADMIN</code> token if only 1 workspace is specified)</li> <li>Your Organization ID</li> <li>The reporting period (start and end dates)</li> </ol> <p>See the Usage Guide for detailed setup instructions.</p>"},{"location":"reports/","title":"Orbis Reports","text":"<p>Orbis generates comprehensive deployment compute reports that provide detailed insights into your Astronomer Software deployments.</p>"},{"location":"reports/#report-components","title":"Report Components","text":""},{"location":"reports/#1-word-document-report","title":"1. Word Document Report","text":"<p>The main report is generated as a Word document containing:</p> <ul> <li>Title page with report metadata</li> <li>Detailed deployment information</li> <li>Statistical analysis and metrics</li> <li>Visualization charts and graphs</li> <li>Query URLs for reference</li> </ul>"},{"location":"reports/#2-csv-report","title":"2. CSV Report","text":"<p>A detailed CSV report containing:</p> <ul> <li>Deployment information (name, namespace, executor type)</li> <li>Scheduler metrics</li> <li>Worker metrics (type, queue name, concurrency)</li> <li>CPU and memory statistics</li> <li>KPO (Kubernetes Pod Operator) metrics where applicable</li> </ul>"},{"location":"reports/#3-data-visualizations","title":"3. Data Visualizations","text":"<p>Interactive graphs and charts showing:</p> <ul> <li>Resource utilization trends</li> <li>Performance metrics over time</li> <li>Statistical measures (mean, median)</li> <li>Adaptive downsampling for large datasets</li> </ul>"},{"location":"reports/#report-generation-process","title":"Report Generation Process","text":"<ol> <li> <p>Data Collection:</p> <ul> <li>Fetches metrics from Prometheus</li> <li>Gathers deployment information via Houston API</li> <li>Collects resource utilization data</li> </ul> </li> <li> <p>Data Processing:</p> <ul> <li>Applies adaptive downsampling for large datasets</li> <li>Calculates statistical measures</li> <li>Processes metrics based on executor type</li> </ul> </li> <li> <p>Visualization:</p> <ul> <li>Generates interactive Plotly graphs</li> <li>Creates separate folders for organizations</li> <li>Customizes layouts for optimal readability</li> </ul> </li> <li> <p>Report Compilation:</p> <ul> <li>Generates Word document with formatted content</li> <li>Creates CSV export with detailed metrics</li> <li>Organizes visualizations and data</li> </ul> </li> </ol>"},{"location":"reports/#output-formats","title":"Output Formats","text":"<ul> <li>Word Document (.docx): Main report with visualizations</li> <li>CSV File: Detailed metric data in tabular format</li> <li>JSON Data: Raw report data for further processing</li> <li>Shareable via pre-signed URL (when using <code>-p</code> flag)</li> <li>Combined ZIP archive (when using <code>-z</code> flag)</li> </ul>"},{"location":"reports/#accessing-reports","title":"Accessing Reports","text":"<p>Reports are generated in the <code>output</code> directory when using Docker: <pre><code>docker run --rm -it \\\n  --env-file .env \\\n  -v $(pwd)/output:/app/output \\\n  quay.io/astronomer/orbis:0.7.0 orbis compute-software \\\n  -s START_DATE -e END_DATE -o ORGANIZATION_ID\n</code></pre></p>"},{"location":"modules/data_models/","title":"Data Models for Metrics","text":"<p>The data models in <code>models.py</code> are designed with a strong focus on metrics, allowing for efficient storage and manipulation of various deployment metrics. These models provide a structured way to represent and work with metric data throughout the Orbis system.</p>"},{"location":"modules/data_models/#metric-focused-design","title":"Metric-Focused Design","text":"<ol> <li> <p>Metric Class: This is the core model for representing individual metrics. It includes:</p> <ul> <li>Metric identifier and name</li> <li>Associated queries</li> <li>Aggregators and table headers</li> <li>Worker queue information</li> <li>Executor type</li> </ul> </li> <li> <p>MetricCalculation Class: Represents calculated values for a specific metric, including:</p> <ul> <li>Mean, median, max, min, and 90<sup>th</sup> percentile values</li> <li>Optional worker queue statistics</li> </ul> </li> <li> <p>WorkerQueueStats Class: Stores detailed statistics for individual worker queues, allowing for granular analysis of queue performance.</p> </li> <li> <p>Figure Class: Represents a generated visualization of a metric, linking the metric data with its visual representation.</p> </li> <li> <p>NamespaceReport and OverallReport Classes: These classes aggregate metric calculations for namespaces and the entire organization, respectively.</p> </li> </ol>"},{"location":"modules/data_models/#flexibility-for-new-metrics","title":"Flexibility for New Metrics","text":"<p>Adding new metrics to the system is relatively straightforward:</p> <ol> <li> <p>YAML Configuration: Add the new metric queries to the YAML configuration file.</p> </li> <li> <p>Model Updates: In most cases, no changes to the existing models are required. The <code>Metric</code> class is designed to accommodate various types of metrics.</p> </li> <li> <p>Processing Logic: Update the processing logic in <code>generator.py</code> and <code>csv_generator.py</code> to handle the new metric if it requires special treatment.</p> </li> </ol>"},{"location":"modules/data_models/#extensibility","title":"Extensibility","text":"<p>The current model structure allows for easy extension:</p> <ol> <li> <p>New Attributes: If a new metric requires additional attributes, they can be added to the <code>Metric</code> or <code>MetricCalculation</code> classes.</p> </li> <li> <p>New Models: For entirely new types of metrics or data, new dataclasses can be created following the existing pattern.</p> </li> <li> <p>Inheritance: The existing classes can be extended through inheritance if more specialized metric types are needed.</p> </li> </ol> <p>This metric-focused design ensures that Orbis can efficiently handle a wide range of metrics while remaining flexible for future additions and changes.</p>"},{"location":"modules/api/houston/","title":"Houston API Integration","text":"<p>The <code>houston.py</code> module is a crucial component of Orbis, leveraging the Houston API to retrieve essential deployment information. This module provides a comprehensive interface to gather metadata about an BASEDOMAIN, its workspaces and deployments, which is fundamental for targeted metric collection.</p>"},{"location":"modules/api/houston/#key-components","title":"Key Components","text":""},{"location":"modules/api/houston/#api-class","title":"API Class","text":"<p>This class encapsulates all interactions with the Houston API:</p> <ul> <li>Handles authentication and request headers</li> <li>Provides methods for various API endpoints (base_domain, workspaces, deployments)</li> <li>Implements error handling and response validation</li> </ul>"},{"location":"modules/api/houston/#utility-functions","title":"Utility Functions","text":"<p>Several utility functions build upon the CoreAPI class to provide higher-level functionality:</p> <ul> <li><code>get_organization_metadata</code>: Retrieves BASEDOMAIN and associated namespaces</li> <li><code>get_cluster_wise_deployments</code>: Groups deployments by clusters</li> <li><code>get_deployment_wise_queues</code>: Fetches detailed information about worker queues for each deployment</li> </ul>"},{"location":"modules/api/houston/#leveraging-houston-api-for-deployment-data","title":"Leveraging Houston API for Deployment Data","text":"<p>The module efficiently utilizes the Astro API to gather comprehensive deployment information:</p> <ol> <li>Cluter-Level Data:<ul> <li>Fetches BASEDOMAIN metadata</li> <li>Retrieves a list of all namespaces within the cluster</li> <li>Obtains workspace details for a cluster</li> <li>Groups deployments by their associated worksapces</li> <li>Gathers detailed metadata for each deployment</li> <li>Extracts information about executor type, scheduler configuration, and worker queues</li> <li>Includes information like queue names, worker types, concurrency, and scaling limits</li> </ul> </li> </ol>"},{"location":"modules/api/houston/#why-resource-conversion-is-needed-in-software","title":"Why resource conversion is needed in Software","text":"<p>As software does not have fixed size machines and has custom resource allocator (which can be either completely custom resources or Astronomer units), orbis fetches them to provide an idea of the component sizes as compared to resource utilization. Some deployments may have ample resources allocated but utilizing only a fraction of it.</p>"},{"location":"modules/api/houston/#computing-resources-for-software","title":"Computing resources for Software","text":"<ul> <li>Maximum Worker count: replicas</li> <li>Minimum Worker count: 1 (Defaulted)</li> <li>Worker Concurrency: From Environment Variable, if not set, default to 16 <p><code>Note:</code> If environment variable is set with Dockerfile, this will not be considered.</p> </li> <li>Worker Type: Allocated worker limit resources</li> </ul>"},{"location":"modules/api/houston/#formulas-to-convert-custom-resources-to-aus","title":"Formulas to convert custom resources to AUs:","text":"<ul> <li>Memory: resources[\"memory\"] / 384</li> <li> <p>CPU: resources[\"cpu\"] / 100</p> </li> <li> <p>If AU conversion possible, then AUs = any(Memory in AUs, CPU in AUs)</p> </li> <li>If AU conversion not possible, then AUs = [Memory in GB, CPU in vCPU] <p><code>Note:</code> AU conversion possible if the memory is in multiples of 384 and CPU is in multiples of 100 and both are same values.</p> </li> </ul>"},{"location":"modules/api/houston/#integration-with-orbis-workflow","title":"Integration with Orbis Workflow","text":"<p>This module plays a vital role in Orbis's operation:</p> <ol> <li>It provides the necessary context for metric collection, ensuring that Orbis targets the correct deployments and namespaces.</li> <li>The deployment configurations retrieved are used to populate the <code>DeploymentConfig</code> and <code>WorkerQueueStats</code> models.</li> <li>This information guides the metric collection process in <code>prometheus.py</code> and the report generation in <code>generator.py</code>.</li> </ol> <p>By leveraging the Houston API, Orbis can dynamically adapt to the current state of a Software deployment, ensuring accurate and relevant metric collection and reporting.</p>"},{"location":"modules/api/prometheus/","title":"Prometheus Data Fetching","text":"<p>The <code>PrometheusData</code> class in <code>prometheus.py</code> is crucial for populating the metric models with real-time data from Prometheus. It provides an efficient and robust mechanism for fetching large amounts of data over extended time periods.</p>"},{"location":"modules/api/prometheus/#key-features","title":"Key Features","text":"<ol> <li>Asynchronous Data Fetching: Utilizes <code>asyncio</code> for non-blocking API calls, improving performance.</li> <li>Batched Queries: Implements a batching mechanism to handle large date ranges without overwhelming the Prometheus API or client.</li> <li>Error Handling: Robust error handling for API failures and data inconsistencies.</li> <li>Data Processing: Converts raw API responses into Polars DataFrames for efficient data manipulation.</li> </ol>"},{"location":"modules/api/prometheus/#data-fetching-mechanism","title":"Data Fetching Mechanism","text":"<p>The <code>query_over_range</code> method implements a sophisticated batching strategy:</p> <ol> <li>Time Period Division: The total query time range is divided into smaller periods (default 6 hours).</li> <li>Parallel Queries: Multiple queries are executed in parallel for each time period.</li> <li>Data Aggregation: Results from all periods are combined into a single DataFrame.</li> <li>Data Cleaning: Duplicate timestamps are removed, and values are sorted and cast to the appropriate data type.</li> </ol> <p>This approach allows Orbis to fetch and process data for extended time ranges that would typically cause issues in the Prometheus web UI.</p>"},{"location":"modules/api/prometheus/#populating-models","title":"Populating Models","text":"<p>The <code>PrometheusData</code> class doesn't directly populate the models but provides the raw data needed:</p> <ol> <li>The <code>query_over_range</code> method returns a Polars DataFrame with timestamp and value columns.</li> <li>This DataFrame is then used in <code>generator.py</code> to create <code>Figure</code> objects and calculate metrics.</li> <li>The calculated metrics are used to populate <code>MetricCalculation</code> and <code>NamespaceReport</code> objects.</li> </ol>"},{"location":"modules/api/prometheus/#extensibility","title":"Extensibility","text":"<p>Adding new metrics or modifying existing ones primarily involves:</p> <ol> <li>Updating the query strings passed to <code>query_over_range</code>.</li> <li>Adjusting the data processing logic in <code>generator.py</code> if the new metric requires special handling.</li> </ol> <p>The <code>PrometheusData</code> class itself rarely needs modification when adding new metrics, making it a stable foundation for Orbis's data fetching needs.</p>"},{"location":"modules/api/prometheus/#queries","title":"Queries","text":"<p>The <code>PrometheusData</code> class uses a list of queries to fetch data from the Prometheus API. These queries are divided into batches and executed in parallel to improve performance.</p>"},{"location":"modules/api/prometheus/#prometheus-queries","title":"Prometheus Queries","text":"<p>This document details all the Prometheus queries used by Orbis to collect metrics.</p> <pre><code># Scheduler CPU usage rate over 5-minute intervals\nrate(container_cpu_usage_seconds_total{namespace=\"astronomer-optical-illusion-5432\", container=\"scheduler\"}[5m])\n\n# Scheduler memory usage in gigabytes\nmax(container_memory_working_set_bytes{namespace=\"astronomer-optical-illusion-5432\", container=\"scheduler\"}) by (pod)\n/(1024 * 1024 *1024)\n\n# Total count of successful task instances\nsum(airflow_ti_successes{release=\"optical-illusion-5432\"})\n\n# Total count of failed task instances\nsum(airflow_ti_failures{release=\"optical-illusion-5432\"})\n\n# Hourly increase in successful tasks\nmax(round(increase(airflow_ti_successes{release=\"optical-illusion-5432\"}[1h])))\n\n# Hourly increase in failed tasks\nmax(round(increase(airflow_ti_failures{release=\"optical-illusion-5432\"}[1h])))\n\n# Celery workers CPU usage rate over 5-minute intervals\nrate(container_cpu_usage_seconds_total{namespace=\"astronomer-optical-illusion-5432\", container=\"worker\", pod=~\"astronomer-optical-illusion-5432-worker-.*\"}[5m])\n\n# Celery workers memory usage in gigabytes\nmax(container_memory_working_set_bytes{namespace=\"astronomer-optical-illusion-5432\", container=\"worker\", pod=~\"astronomer-optical-illusion-5432-worker-.*\"}) by (pod)\n/(1024 * 1024 *1024)\n\n# Count of Celery worker pods\ncount(kube_pod_info{namespace=\"astronomer-optical-illusion-5432\", pod=~\"astronomer-optical-illusion-5432-worker-.*\"})\n\n# Kubernetes Pod Operator CPU usage\nsum(\n  kube_pod_labels{label_airflow_kpo_in_cluster=\"True\",namespace=\"astronomer-optical-illusion-5432\"}\n  * on (pod) group_left()\n  sum by (pod) (\n    rate(container_cpu_usage_seconds_total{namespace=\"astronomer-optical-illusion-5432\",pod!~\"astronomer-optical-illusion-5432-.*\"}[5m])\n  )\n)\n\n# Kubernetes Pod Operator memory usage in gigabytes\nsum(\n  kube_pod_labels{label_airflow_kpo_in_cluster=\"True\",namespace=\"astronomer-optical-illusion-5432\"}\n  * on (pod) group_left()\n  max by (pod) (\n    container_memory_working_set_bytes{namespace=\"astronomer-optical-illusion-5432\",pod!~\"astronomer-optical-illusion-5432-.*\"}\n  )\n)/(1024 * 1024 *1024)\n\n# Kubernetes Executor CPU usage\nsum(\n  (kube_pod_labels{{label_airflow_worker!=\"\",namespace=\"astronomer-optical-illusion-5432\"}}\n  * on (pod) group_left()\n  sum by (pod) (\n    rate(\n      container_cpu_usage_seconds_total{{namespace=\"astronomer-optical-illusion-5432\",pod!~\"optical-illusion-5432-worker-.*\"}}[5m]\n    )\n  ))\nor\n  (kube_pod_labels{{label_airflow_kpo_in_cluster=\"True\",namespace=\"astronomer-optical-illusion-5432\"}}\n  * on (pod) group_left()\n  sum by (pod) (\n    rate(\n      container_cpu_usage_seconds_total{{namespace=\"astronomer-optical-illusion-5432\",pod!~\"optical-illusion-5432-worker-.*\"}}[5m]\n    )\n  ))\n)\n\n# Kubernetes Executor memory usage in gigabytes\nsum(\n  (kube_pod_labels{{label_airflow_worker!=\"\",namespace=\"astronomer-optical-illusion-5432\"}}\n  * on (pod) group_left()\n  sum by (pod) (\n    container_memory_working_set_bytes{{container!=\"\",image!=\"\",namespace=\"astronomer-optical-illusion-5432\"}}\n  ))\nor\n  (kube_pod_labels{{label_airflow_kpo_in_cluster=\"True\",namespace=\"astronomer-optical-illusion-5432\"}}\n  * on (pod) group_left()\n  sum by (pod) (\n    container_memory_working_set_bytes{{container!=\"\",image!=\"\",namespace=\"astronomer-optical-illusion-5432\"}}\n  ))\n)/(1024 * 1024 * 1024)\n</code></pre>"},{"location":"modules/api/prometheus/#metric-aggregation","title":"Metric Aggregation","text":"<p>For each metric, we calculate the following aggregations:</p> <ul> <li>Minimum value</li> <li>Maximum value</li> <li>Mean value</li> <li>Median value</li> </ul> <p>These aggregations help provide a comprehensive view of the metric's behavior over time.</p>"},{"location":"modules/report/csv_generator/","title":"CSV Generator","text":"<p>The CSV Generator module is responsible for creating a CSV report from the overall deployment compute data. It provides functions to process and format the data according to a predefined CSV template.</p>"},{"location":"modules/report/csv_generator/#main-functions","title":"Main Functions","text":""},{"location":"modules/report/csv_generator/#generate_csv_from_report","title":"generate_csv_from_report","text":"<p>This function is the entry point for CSV generation. It takes an <code>OverallReport</code> object and a file path, then writes the formatted data to a CSV file.</p>"},{"location":"modules/report/csv_generator/#process_namespace_report","title":"process_namespace_report","text":"<p>Processes a single <code>NamespaceReport</code> and returns a list of dictionaries representing rows in the CSV file. It handles different executor types (Kubernetes and Celery) and their specific metrics.</p>"},{"location":"modules/report/csv_generator/#helper-functions","title":"Helper Functions","text":"<ul> <li><code>create_base_row</code>: Creates a base dictionary with common deployment information.</li> <li><code>update_scheduler_metrics</code>: Updates the row with scheduler-specific metrics.</li> <li><code>update_kubernetes_worker_metrics</code>: Adds Kubernetes worker metrics to the row.</li> <li><code>update_celery_cpu_metrics</code>: Processes Celery CPU metrics for each worker queue.</li> <li><code>update_celery_memory_metrics</code>: Adds Celery memory metrics for each worker queue.</li> <li><code>update_celery_kpo_metrics</code>: Handles Celery KPO (Kubernetes Pod Operator) specific metrics.</li> </ul>"},{"location":"modules/report/csv_generator/#data-processing","title":"Data Processing","text":"<p>The module handles different executor types (Kubernetes and Celery) and their specific metrics. For Celery executors, it creates separate rows for each worker queue and an additional row for KPO metrics if applicable.</p>"},{"location":"modules/report/csv_generator/#csv-structure","title":"CSV Structure","text":"<p>The CSV file follows a predefined template structure, which includes: - Deployment information (name, namespace, executor type) - Scheduler metrics - Worker metrics (type, queue name, concurrency, etc.) - CPU and memory statistics for both scheduler and workers</p> <p>This module ensures that the complex deployment data is formatted into a clear, tabular format for easy analysis and reporting.</p>"},{"location":"modules/report/generator/","title":"Report Generator","text":"<p>The Report Generator module is responsible for creating comprehensive deployment compute reports. It consists of two main components: the <code>generate_report</code> function and the <code>ReportGenerator</code> class.</p>"},{"location":"modules/report/generator/#generate_report-function","title":"generate_report Function","text":"<p>This function orchestrates the entire report generation process:</p> <ol> <li>Fetches data from Chronosphere for specified metrics and namespaces using <code>get_metrics_data_and_plot</code>.</li> <li>Processes data and generates visualizations (figures) for each metric.</li> <li>Creates an overall report structure containing detailed information for each namespace.</li> <li>Generates a Word document report using the <code>ReportGenerator</code> class.</li> <li>Exports the report data to JSON and CSV formats using <code>json.dump</code> and <code>generate_csv_from_report</code> respectively.</li> </ol>"},{"location":"modules/report/generator/#reportgenerator-class","title":"ReportGenerator Class","text":"<p>This class handles the creation and formatting of the Word document report:</p> <ol> <li><code>setup_document</code>: Sets up the document structure with proper margins and headers/footers.</li> <li><code>add_title_page</code>: Creates a title page with report metadata.</li> <li><code>add_figure</code>: Adds figures (charts) to the document.</li> <li><code>add_statistics_table</code>: Includes statistics tables for each metric.</li> <li><code>add_visualization_url</code>: Adds URLs for each query.</li> <li><code>save_document</code>: Saves the formatted document.</li> </ol> <p>The <code>ReportGenerator</code> class allows the <code>generate_report</code> function to focus on data processing and overall report structure, while delegating the specifics of document creation to this specialized class. This separation of concerns enhances modularity and maintainability of the code.</p>"},{"location":"modules/report/visualizer/","title":"Visualizer and Data Transformation","text":"<p>The Visualizer module in Orbis is responsible for creating high-quality, informative graphs from metric data. It works in tandem with advanced data transformation techniques to ensure optimal visualization even for large datasets.</p>"},{"location":"modules/report/visualizer/#visualizer-class","title":"Visualizer Class","text":"<p>The Visualizer class is the core component for generating graphs:</p>"},{"location":"modules/report/visualizer/#key-features","title":"Key Features:","text":"<ul> <li>Creates separate folders for each organization and namespace</li> <li>Generates graphs using Plotly</li> <li>Supports multiple data series on a single graph</li> <li>Calculates and displays statistical measures (mean, median)</li> <li>Customizes y-axis labels based on metric type</li> <li>Implements adaptive downsampling for large datasets</li> </ul>"},{"location":"modules/report/visualizer/#main-methods","title":"Main Methods:","text":"<ul> <li><code>generate_graph</code>: Creates a graph for a given metric and set of dataframes</li> <li><code>get_y_axis_label</code>: Determines appropriate y-axis label based on metric type</li> <li><code>update_layout</code>: Customizes the graph layout for optimal readability</li> </ul>"},{"location":"modules/report/visualizer/#adaptive-downsampling","title":"Adaptive Downsampling","text":"<p>The adaptive downsampling technique, implemented in <code>transform.py</code>, is a powerful feature that allows Orbis to handle extremely large datasets efficiently:</p>"},{"location":"modules/report/visualizer/#how-it-works","title":"How it works:","text":"<ol> <li>Divides the data into windows of a specified size</li> <li>Calculates the rate of change within each window</li> <li>If the rate of change exceeds a threshold, all points in the window are kept</li> <li>If the rate of change is below the threshold, only the mean value is kept</li> <li>Adjusts the threshold dynamically to ensure the final dataset size is manageable</li> </ol>"},{"location":"modules/report/visualizer/#benefits","title":"Benefits:","text":"<ul> <li>Preserves important data fluctuations</li> <li>Significantly reduces dataset size for faster rendering</li> <li>Maintains visual accuracy of the graph</li> </ul>"},{"location":"modules/report/visualizer/#integration","title":"Integration","text":"<p>The Visualizer class seamlessly integrates the adaptive downsampling technique:</p> <ol> <li>It checks if the dataset size exceeds a threshold (3,500,000 rows)</li> <li>If so, it calls the <code>adaptive_downsample</code> function</li> <li>The downsampled data is then used to create the graph</li> </ol> <p>This integration ensures that Orbis can handle datasets of any size while still producing clear, informative visualizations. The combination of the Visualizer class and adaptive downsampling makes Orbis a powerful tool for analyzing and presenting complex metric data.</p>"},{"location":"usage/software_usage/","title":"Orbis Usage Guide for Software","text":"<p>This guide explains how to use Orbis to generate compute reports for Astronomer Software deployments.</p>"},{"location":"usage/software_usage/#prerequisites","title":"Prerequisites","text":"<ol> <li>Docker installed (recommended)</li> <li>Houston API token with SYSTEM_ADMIN role (or WORKSPACE_ADMIN role if only 1 workspace is specified)</li> <li>Organization domain for Astronomer Software</li> <li>Start and end dates for the report period</li> </ol>"},{"location":"usage/software_usage/#using-docker-recommended","title":"Using Docker (Recommended)","text":"<ol> <li> <p>Create a <code>.env</code> file with your configuration:    <pre><code>ASTRO_SOFTWARE_API_TOKEN=your_token_here\n</code></pre></p> </li> <li> <p>Run Orbis using Docker:    <pre><code>docker run --pull always --rm -it \\\n  --env-file .env \\\n  -v $(pwd)/output:/app/output \\\n  quay.io/astronomer/orbis:0.7.0 orbis compute-software \\\n  -s START_DATE \\\n  -e END_DATE \\\n  -o ORGANIZATION_ID \\\n  [-v] [-w WORKSPACES] [-z] [-r] [-p]\n</code></pre></p> </li> </ol>"},{"location":"usage/software_usage/#using-orbis-cli","title":"Using Orbis CLI","text":"<p>Check installation guide for Orbis CLI here</p> <ol> <li> <p>Create a <code>.env</code> file with your configuration:    <pre><code>ASTRO_SOFTWARE_API_TOKEN=your_token_here\n</code></pre></p> </li> <li> <p>Run Orbis using the Orbis CLI:    <pre><code>orbis compute-software \\\n  -s START_DATE \\\n  -e END_DATE \\\n  -o ORGANIZATION_ID \\\n  [-v] [-w WORKSPACES] [-z] [-r] [-p]\n</code></pre></p> </li> </ol>"},{"location":"usage/software_usage/#command-options","title":"Command Options","text":"Option Description <code>-s, --start_date</code> Start date for the report in UTC [format: YYYY-MM-DD] <code>-e, --end_date</code> End date for the report in UTC [format: YYYY-MM-DD] (End date is not inclusive. Example for report till 12th Dec 2024 use 2024-12-13) <code>-o, --organization_id</code> Astronomer organization domain <code>-v, --verbose</code> Enable verbose logging (use -v, -vv, or -vvv for more detailed logging) [Optional] <code>-w, --workspaces</code> Comma-separated list of Workspace IDs [optional] <code>-z, --compress</code> Compress the output reports [optional] <code>-r, --resume</code> Resume report generation from the last saved state [optional] <code>-p, --persist</code> Persist temporary files in output folder [optional] <code>-u, --url</code> Pre-signed URL (in quotes) to upload report [Optional] <code>--verify-ssl</code> Enable or disable SSL verification for requests. Default is <code>True</code>. Set to <code>False</code> when using self-signed certificates [optional]"},{"location":"usage/software_usage/#example-usage","title":"Example Usage","text":"<pre><code>docker run --pull always --rm -it \\\n  --env-file .env \\\n  -v $(pwd)/output:/app/output \\\n  quay.io/astronomer/orbis:0.7.0 orbis compute-software \\\n  -s 2024-01-01 \\\n  -e 2024-01-31 \\\n  -o org-abcd1234 \\\n  -v\n</code></pre>"},{"location":"usage/software_usage/#generate-system-admin-level-api-token","title":"Generate System Admin Level API Token","text":"<ul> <li>Orbis won't be able to query Prometheus without the SYSTEM_ADMIN token.</li> <li>Go to <code>https://houston.&lt;organization_domain&gt;/v1</code>.</li> <li> <p>Execute the following query to get create the SYSTEM_ADMIN service account and API token.     <pre><code>mutation create_system_service_account {\n    createSystemServiceAccount(label: \"serv-acc\", role: SYSTEM_ADMIN){\n            apiKey\n        roleBindings{\n            role\n        }\n    }\n}\n</code></pre></p> <p>Sample Response: <pre><code>{\n    \"data\": {\n        \"createSystemServiceAccount\": {\n            \"apiKey\": \"&lt;GENERATED_TOKEN&gt;\",\n            \"roleBindings\": [\n                {\n                    \"role\": \"SYSTEM_ADMIN\"\n                }\n            ]\n        }\n    }\n}\n</code></pre></p> </li> <li> <p>Add the API token to the <code>.env</code> file <code>ASTRO_SOFTWARE_API_TOKEN=&lt;GENERATED_TOKEN&gt;</code></p> </li> </ul>"},{"location":"usage/software_usage/#output","title":"Output","text":"<p>The command generates a comprehensive PDF report in the <code>output</code> directory with metrics as below for the given duration:</p> <ul> <li>Scheduler CPU and Memory</li> <li>Worker CPU and Memory</li> <li>KPO\u2019s CPU and Memory</li> <li>Task Trends</li> <li>Worker (Celery/Kubernetes) Pod Counts</li> </ul>"}]}